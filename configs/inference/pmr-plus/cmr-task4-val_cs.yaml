#ckpt_path: /common/lidxxlab/chushu/augmented_data_training_results/16cascade_with_data_augmentation/cmr2024_2025_augmented/8ydpc561/checkpoints/best-epochepoch=04-valvalidation_loss=0.0225.ckpt
#ckpt_path: /common/lidxxlab/chushu/augmented_data_training_results/16cascade_with_data_augmentation/cmr2024_2025_augmented/8ydpc561/checkpoints/best-epochepoch=05-valvalidation_loss=0.0224.ckpt
#ckpt_path: /common/lidxxlab/Yi/augmented_data_training_results1015/16cascade_with_data_augmentation_continue/cmr2024_2025_augmented/1hgnz3ej/checkpoints/best-epochepoch=04-valvalidation_loss=0.0271.ckpt
#ckpt_path: /common/lidxxlab/chushu/augmented_data_training_results1015/16cascade_with_data_augmentation_continue/cmr2024_2025_augmented/2ob79yr3/checkpoints/best-epochepoch=06-valvalidation_loss=0.0132.ckpt
#ckpt_path: /common/lidxxlab/Yi/augmented_data_training_results1022/16cascade_with_data_augmentation_continue/cmr2024_2025_augmented/hfygjfvh/checkpoints/best-epochepoch=05-valvalidation_loss=0.0167.ckpt
#ckpt_path: /common/lidxxlab/cmrchallenge/task3/PromptMR-plus-Task4_kloss/multi_dataset_training_kloss/promptmr-plus/CMR2024_2025_dataset_specific/cmr2024_2025_phased/63g54ggy/checkpoints/best-epochepoch=09-valvalidation_loss=0.0142.ckpt
#ckpt_path: /common/lidxxlab/Yi/augmented_data_training_results1025_small_fov/16cascade_with_data_augmentation_continue/cmr2024_2025_augmented/b6li5v80/checkpoints/best-epochepoch=03-valvalidation_loss=0.0170.ckpt
ckpt_path: /common/lidxxlab/Yi/augmented_data_training_results1025_intensity_FOV_combined1/16cascade_with_data_augmentation_continue/cmr2024_2025_augmented/wp6m2z1q/restored_ckpts/best-epochepoch=01-valvalidation_loss=0.0145-v2.ckpt
# /common/lidxxlab/chushu/augmented_data_training_results_3T_only_5e-6/16cascade_with_data_augmentation/cmr2024_2025_augmented/rdognlts/checkpoints/best-epochepoch=03-valvalidation_loss=0.0146.ckpt
# /common/lidxxlab/Yi/augmented_data_training_results1025_intensity_FOV_combined1/16cascade_with_data_augmentation_continue/cmr2024_2025_augmented/wp6m2z1q/ckpt_copy/checkpoints/best-epochepoch=02-valvalidation_loss=0.0144-v4.ckpt
# /common/lidxxlab/Yi/augmented_data_training_results1025_intensity_FOV_combined1/16cascade_with_data_augmentation_continue/cmr2024_2025_augmented/wp6m2z1q/checkpoints/best-epochepoch=01-valvalidation_loss=0.0145.ckpt
# /common/lidxxlab/chushu/augmented_data_training_results_3T_only_5e-6/16cascade_with_data_augmentation/cmr2024_2025_augmented/rdognlts/checkpoints/best-epochepoch=01-valvalidation_loss=0.0147.ckpt
#/common/lidxxlab/Yi/augmented_data_training_results1025_intensity_FOV_combined1/16cascade_with_data_augmentation_continue/cmr2024_2025_augmented/u3cd9enj/checkpoints/best-epochepoch=08-valvalidation_loss=0.0147.ckpt
#/common/lidxxlab/cmrchallenge/task3/PromptMR-plus-Task4_kloss/multi_dataset_training_kloss/promptmr-plus/CMR2024_2025_dataset_specific/cmr2024_2025_phased/4011nm3j/checkpoints/best-epochepoch=10-valvalidation_loss=0.0129.ckpt
#/common/lidxxlab/cmrchallenge/task3/PromptMR-plus-Task4_kloss/multi_dataset_training_3T_finetune2/promptmr-plus/CMR2024_2025_dataset_specific/cmr2024_2025_phased/bosarbui/checkpoints/best-epochepoch=00-valvalidation_loss=0.0130.ckpt
#/common/lidxxlab/Yi/augmented_data_training_results1025_intensity_FOV_combined1/16cascade_with_data_augmentation_continue/cmr2024_2025_augmented/dwv7okdy/checkpoints/best-epochepoch=07-valvalidation_loss=0.0127.ckpt
# /common/lidxxlab/cmrchallenge/task3/PromptMR-plus-Task4_kloss/multi_dataset_training_kloss/promptmr-plus/CMR2024_2025_dataset_specific/cmr2024_2025_phased/4011nm3j/checkpoints/best-epochepoch=11-valvalidation_loss=0.0127.ckpt
#/common/lidxxlab/Yi/augmented_data_training_results1022/16cascade_with_data_augmentation_continue/cmr2024_2025_augmented/hfygjfvh/checkpoints/best-epochepoch=03-valvalidation_loss=0.0169.ckpt
# /common/lidxxlab/chushu/training_results_folder/Perfusion_augmented1013/promptmr-plus/CMR2025/deep_recon/wwuzjz0q/checkpoints/epoch=12-step=403890.ckpt
#/common/lidxxlab/Yi/training_results_folder/multi_dataset_training_kloss/promptmr-plus/CMR2024_2025_dataset_specific/cmr2024_2025_phased/z212ttat/checkpoints/best-epochepoch=02-valvalidation_loss=0.0175.ckpt
#/common/lidxxlab/Yi/training_results_folder/multi_dataset_training_kloss/promptmr-plus/CMR2024_2025_dataset_specific/cmr2024_2025_phased/ophww12n/checkpoints/best-epochepoch=08-valvalidation_loss=0.0156.ckpt
data: 
  class_path: pl_modules.InferenceDataModule
  init_args:
    slice_dataset: data.CmrxReconInferenceSliceDataset
    # data_path: /common/lidxxlab/cmrchallenge/data/CMR2025/Validation/Task2/TaskR2/MultiCoil
    # data_path: /common/lidxxlab/cmrchallenge/data/CMR2025/Validation/TaskR1/MultiCoil
    data_path: /common/lidxxlab/cmrchallenge/data/CMR2025/Validation/Task4/TaskS2/MultiCoil
    challenge: multicoil
    test_transform:
      class_path: data.CmrxReconDataTransform

      init_args:
        mask_func: null
        uniform_resolution: null
        use_seed: True
        mask_type: 'cartesian_or_radial'
        test_num_low_frequencies: 16
        uniform_resolution: null
        use_seed: true
        
        # test_num_low_frequencies: -1   # If mask_func is none, use this parameter
    num_adj_slices: 5  # 修改为5，与模型配置一致
    batch_size: 1
    num_workers: 4  # 增加worker数量加速数据加载
    # pin_memory: true
    distributed_sampler: false  # 推理时关闭分布式采样器
    test_filter: 
      class_path: data.FuncFilterString
      init_args:
        filter_str: 


# dataset specific settings
seed_everything: 42
trainer:
  accelerator: gpu
  strategy: auto  # 改为auto，推理时更稳定
  devices: 3      # 推理时建议使用单GPU
  precision: 16 
  num_nodes: 1


  callbacks:
    - class_path: __main__.CustomWriter
      init_args:
        output_dir: /common/lidxxlab/cmrchallenge/code/Inference/3T_only_new_epoch1_v2_2e-6
        #/common/lidxxlab/cmrchallenge/code/Inference/small_FOV1025_epoch3
        write_interval: batch_and_epoch
        

model:
  class_path: pl_modules.PromptMrModule
  init_args:
    # Model architecture 
    num_cascades: 16               # Number of cascade blocks
    num_adj_slices: 5              # Number of adjacent slices
    n_feat0: 48                    # Base feature channels
    
    # Feature dimensions
    feature_dim: [72, 96, 120]     # Feature dimensions for three levels
    prompt_dim: [24, 48, 72]       # Prompt dimensions for three levels
    
    # Sensitivity coil parameters
    sens_n_feat0: 24               # Base feature channels for sensitivity coil
    sens_feature_dim: [36, 48, 60] # Feature dimensions for sensitivity coil
    sens_prompt_dim: [12, 24, 36]  # Prompt dimensions for sensitivity coil
    
    # Prompt parameters
    len_prompt: [5, 5, 5]          # Number of prompt components for each level
    prompt_size: [64, 32, 16]      # Spatial size of prompt features
    
    # Network components
    n_enc_cab: [2, 3, 3]           # Number of encoder CABs
    n_dec_cab: [2, 2, 3]           # Number of decoder CABs
    n_skip_cab: [1, 1, 1]          # Number of skip connection CABs
    n_bottleneck_cab: 3            # Number of bottleneck CABs
    
    # Feature switches
    no_use_ca: false               # Whether not to use channel attention
    learnable_prompt: false        # Whether prompt parameters are learnable
    adaptive_input: true           # Whether to use adaptive input
    n_buffer: 4                    # Buffer size
    n_history: 15                  # Number of history features
    use_sens_adj: true             # Whether to use sensitivity coil adjacency processing
    
    # Other parameters
    use_checkpoint: false          # Whether to use gradient checkpointing
    compute_sens_per_coil: false   # Whether to compute sensitivity map per coil
    pretrain: false                # Whether to use pretraining
    pretrain_weights_path: null
    num_log_images: 16             # Number of images to log


# python main.py predict --config configs/inference/pmr-plus/cmr-task4-val_cs.yaml