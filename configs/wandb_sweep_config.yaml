# Wandb Sweep Configuration for PromptMR
program: main.py
method: bayes  # Options: grid, random, bayes
metric:
  goal: maximize
  name: val_metrics/ssim
parameters:
  # Hyperparameters to optimize
  model.init_args.weight_decay:
    distribution: log_uniform_values
    min: 0.0001
    max: 0.1
  model.init_args.lr_gamma:
    values: [0.05, 0.1, 0.15, 0.2, 0.3]
  model.init_args.num_adj_slices:
    values: [3, 5, 7, 9]
  model.init_args.num_cascades:
    values: [8, 12, 16, 20]
  model.init_args.lr:
    distribution: log_uniform_values
    min: 0.00001
    max: 0.001

# Early termination to stop poor performing runs
early_terminate:
  type: hyperband
  min_iter: 5  # Minimum epochs before termination
  eta: 2       # Reduction factor
  s: 3         # Number of brackets

# Command to run (this gets executed by agents)
command:
  - python
  - main.py
  - fit
  - --config
  - configs/base.yaml
  - --config
  - configs/model/pmr-plus.yaml
  - --config
  - configs/train/pmr-plus/pmr-plus.yaml
  - --trainer.max_epochs
  - "12"
  - --trainer.logger.class_path
  - lightning.pytorch.loggers.WandbLogger
  - --trainer.logger.init_args.project
  - promptmr-sweep
  - --trainer.logger.init_args.tags
  - "[sweep, hyperopt]"
  - ${args}  # This gets replaced with sweep parameters